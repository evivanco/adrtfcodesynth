{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5245af2-275f-4e7b-9e20-331ccd39a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\.conda\\envs\\openai_arq_last\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fb9c5c-41a8-4c1f-9b72-dc25649e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api = os.getenv(\"AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a45846-f225-47a1-9a47-dcd1810cd6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Introductory Markdown generated and saved to 'intro_architecture.md' ===\n",
      "\n",
      "# Software Architecture\n",
      "\n",
      "## Definition\n",
      "Software architecture refers to the high-level structure of a software system, encompassing the set of structures needed to reason about the system, which comprise software elements, relations among them, and properties of both. It serves as a blueprint for both the system and the project developing it, defining the system's components and their interactions.\n",
      "\n",
      "## Key Characteristics\n",
      "- **Abstraction**: Provides a high-level view of the system, abstracting away from the details of implementation.\n",
      "- **Modularity**: Divides the system into distinct components or modules, each with specific responsibilities.\n",
      "- **Scalability**: Facilitates the system's ability to handle growth in workload or scope.\n",
      "- **Interoperability**: Ensures components can work together and communicate effectively.\n",
      "- **Performance**: Addresses the system's ability to meet performance requirements.\n",
      "- **Security**: Incorporates mechanisms to protect the system from threats and vulnerabilities.\n",
      "\n",
      "## Main Advantages\n",
      "- **Guidance**: Offers a clear framework for development and decision-making.\n",
      "- **Consistency**: Ensures uniformity in design and implementation across the system.\n",
      "- **Risk Management**: Identifies and mitigates potential risks early in the development process.\n",
      "- **Stakeholder Communication**: Provides a common language for discussing system design with stakeholders.\n",
      "\n",
      "## Main Disadvantages\n",
      "- **Complexity**: Can become overly complex, especially in large systems, making it difficult to manage.\n",
      "- **Rigidity**: May lead to inflexibility if not designed with adaptability in mind.\n",
      "- **Initial Overhead**: Requires significant upfront effort and resources to design and document.\n",
      "\n",
      "# Monolithic Architecture\n",
      "\n",
      "## Definition\n",
      "Monolithic architecture is a software design pattern where a software application is built as a single, indivisible unit. This architecture typically involves a single executable or codebase that includes all the necessary components and functionalities.\n",
      "\n",
      "## Key Characteristics\n",
      "- **Single Codebase**: All components are part of a single codebase and are deployed together.\n",
      "- **Tightly Coupled**: Components are often tightly integrated, leading to dependencies between them.\n",
      "- **Unified Deployment**: The entire application is deployed as a single unit.\n",
      "- **Centralized Data Management**: Typically uses a single database for the entire application.\n",
      "\n",
      "## Main Advantages\n",
      "- **Simplicity**: Easier to develop and test due to its unified nature.\n",
      "- **Performance**: Can offer better performance due to reduced inter-process communication.\n",
      "- **Ease of Deployment**: Simplifies deployment as there is only one unit to manage.\n",
      "\n",
      "## Main Disadvantages\n",
      "- **Scalability Limitations**: Difficult to scale horizontally due to its monolithic nature.\n",
      "- **Maintenance Challenges**: Changes in one part of the application can affect the entire system.\n",
      "- **Limited Flexibility**: Hard to adopt new technologies or make architectural changes.\n",
      "\n",
      "# Microservices Architecture\n",
      "\n",
      "## Definition\n",
      "Microservices architecture is a design pattern where a software application is composed of small, independent services that communicate over a network. Each service is focused on a specific business capability and can be developed, deployed, and scaled independently.\n",
      "\n",
      "## Key Characteristics\n",
      "- **Decentralized**: Each service is a separate entity with its own codebase and database.\n",
      "- **Loosely Coupled**: Services are designed to be independent, minimizing dependencies.\n",
      "- **Service-Oriented**: Each service is responsible for a specific business function.\n",
      "- **Polyglot Persistence**: Allows the use of different data storage technologies for different services.\n",
      "\n",
      "## Main Advantages\n",
      "- **Scalability**: Services can be scaled independently based on demand.\n",
      "- **Flexibility**: Facilitates the adoption of new technologies and practices.\n",
      "- **Resilience**: Failure in one service does not necessarily impact others.\n",
      "- **Continuous Deployment**: Enables frequent and independent deployment of services.\n",
      "\n",
      "## Main Disadvantages\n",
      "- **Complexity**: Increases the complexity of system management and communication.\n",
      "- **Network Latency**: Introduces potential latency due to inter-service communication.\n",
      "- **Data Consistency**: Ensuring data consistency across services can be challenging.\n",
      "- **Operational Overhead**: Requires sophisticated infrastructure for deployment and monitoring.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "\n",
    "intro_prompt = \"\"\"\n",
    "Explain the following concepts in clear technical English using Markdown:\n",
    "\n",
    "1. What is software architecture?\n",
    "2. What is a monolithic architecture?\n",
    "3. What is a microservices-based architecture?\n",
    "\n",
    "Structure the answer exactly with these top-level headings:\n",
    "\n",
    "# Software Architecture\n",
    "# Monolithic Architecture\n",
    "# Microservices Architecture\n",
    "\n",
    "For each heading:\n",
    "- Provide a concise definition.\n",
    "- List key characteristics.\n",
    "- Briefly mention main advantages.\n",
    "- Briefly mention main disadvantages.\n",
    "\n",
    "Target audience: expert software architects and senior software engineers.\n",
    "Keep the explanation focused, technically rigorous, and avoid marketing language.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # or the model you are using in the rest of the notebook\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a software architect and professor who explains concepts clearly using Markdown.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": intro_prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "intro_markdown = response.choices[0].message.content\n",
    "\n",
    "# Save the Markdown to a file so it can be reused later in the notebook or exported\n",
    "with open(\"intro_architecture.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(intro_markdown)\n",
    "\n",
    "print(\"=== Introductory Markdown generated and saved to 'intro_architecture.md' ===\")\n",
    "print()\n",
    "print(intro_markdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a16efdb-e5ed-49ee-bcde-3ce1f8413da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) **Assessment**: The provided `main.tf` does not describe a microservices architecture.\n",
      "\n",
      "2) **Justification**:\n",
      "\n",
      "   - **Modularity**: \n",
      "     - There is no evidence of modularity in the `main.tf` file. The absence of Terraform modules or separate directories for services indicates a lack of modular design [R2]. The code does not demonstrate separation by service or function, which is a hallmark of microservices architecture.\n",
      "   \n",
      "   - **Independent Deployment of Services**:\n",
      "     - The Terraform configuration does not specify any independent deployment units such as ECS services, Lambda functions, or Kubernetes deployments [R1]. The configuration appears to be more focused on infrastructure setup rather than defining deployable services.\n",
      "   \n",
      "   - **Communication Style**:\n",
      "     - There is no evidence of asynchronous communication mechanisms such as SQS, SNS, or EventBridge [R4]. The lack of these elements suggests a potential reliance on synchronous communication, which is more typical of monolithic architectures.\n",
      "   \n",
      "   - **Distributed Deployment**:\n",
      "     - The configuration does not demonstrate a distributed deployment across multiple availability zones or regions [R5]. There are no subnet definitions or load balancers that would indicate a distributed, fault-tolerant setup. The configuration appears to be more centralized, which is characteristic of monolithic systems.\n",
      "\n",
      "3) **Negative Signals**:\n",
      "   - The configuration lacks distinct service definitions, suggesting a single deployment unit, which is indicative of a monolithic architecture [R1].\n",
      "   - There is a strong indication of shared state, as evidenced by the use of a single VPC and lack of service-specific databases or state separation [R2].\n",
      "   - The absence of any orchestration or service discovery mechanisms further points towards a tightly-coupled design [R3].\n",
      "\n",
      "4) **Verdict and Confidence Score**:\n",
      "   - **Verdict**: The configuration does not represent a microservices architecture.\n",
      "   - **Confidence Score**: 0.2\n",
      "   - **Explanation**: The lack of modularity, independent service deployment, asynchronous communication, and distributed deployment strongly suggests a monolithic architecture.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"microservices\": false,\n",
      "  \"confidence\": 0.2,\n",
      "  \"signals_for\": [],\n",
      "  \"signals_against\": [\n",
      "    \"lack of modularity\",\n",
      "    \"single deployment unit\",\n",
      "    \"absence of async communication\",\n",
      "    \"centralized deployment\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Analysis saved in 'chef_architecture_analysis1.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "repoExport = \"chef_\"\n",
    "# Read main.tf content\n",
    "with open(repoExport + \"cloud_evolucion_menor.tf\", \"r\", encoding=\"utf-8\") as f:\n",
    "    terraform_code = f.read()\n",
    "\n",
    "# Read IaC rule catalog\n",
    "with open(\"IAC.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    iac_rules = f.read()\n",
    "\n",
    "# Build the user prompt, injecting theoretical context + IaC rules + Terraform code\n",
    "user_prompt = f\"\"\"\n",
    "THEORETICAL CONTEXT (Markdown, for expert architects):\n",
    "{intro_markdown}\n",
    "\n",
    "IAC RULE CATALOG — prioritize this evidence:\n",
    "{iac_rules}\n",
    "\n",
    "TERRAFORM CODE (main.tf):\n",
    "{terraform_code}\n",
    "\n",
    "TASK:\n",
    "1) Decide whether main.tf describes a MICROservices architecture (true/false).\n",
    "2) Justify your assessment with explicit evidence, citing from:\n",
    "   - [R#] for rule references from the IAC catalog, and\n",
    "   - [C#] for specific code fragments in main.tf.\n",
    "   Cover at least:\n",
    "   - modularity (modules/reuse),\n",
    "   - independent deployment of services,\n",
    "   - communication style (async queues/events/APIs),\n",
    "   - distributed deployment (networks/subnets, multiple services, orchestrators).\n",
    "3) Explicitly mention negative signals that point towards a monolith or tightly-coupled design\n",
    "   (single deployment unit, one service, strong shared state, etc.).\n",
    "4) Provide a clear verdict and a confidence score in [0..1] with a short explanation.\n",
    "5) At the very end of the answer, emit a compact JSON mini-report in a single code block,\n",
    "   with the following structure and no extra commentary:\n",
    "\n",
    "{{\n",
    "  \"microservices\": true/false,\n",
    "  \"confidence\": <float between 0 and 1>,\n",
    "  \"signals_for\": [\"...\", \"...\"],\n",
    "  \"signals_against\": [\"...\", \"...\"]\n",
    "}}\n",
    "\n",
    "Be concise, technical, and always cite [R#] and/or [C#] in each justification bullet.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert software architect in Infrastructure as Code and \"\n",
    "                \"cloud-native microservices. You reason rigorously and write for expert architects.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=1200,\n",
    ")\n",
    "\n",
    "text = response.choices[0].message.content.strip()\n",
    "print(text)\n",
    "\n",
    "# Save the full analysis (narrative + JSON mini-report at the end)\n",
    "output_filename = repoExport + \"architecture_analysis1.txt\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(f\"Analysis saved in '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dadee2c1-56bc-4664-8674-3bd7e61dfe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Improved Architecture Analysis\n",
      "\n",
      "## 1. Validation of Previous Terraform-Based Analysis\n",
      "\n",
      "### Validation of Modularity\n",
      "The source code confirms the previous analysis regarding the lack of modularity. The Terraform configuration does not utilize modules or separate directories for different services, which is a key feature of microservices architecture. The codebase is structured in a way that suggests a monolithic approach, with a single deployment unit and shared resources.\n",
      "\n",
      "### Validation of Independent Deployment\n",
      "The source code does not include configurations for independent deployment units such as ECS services, Lambda functions, or Kubernetes pods. This aligns with the previous analysis that highlighted the absence of independent deployment capabilities, further indicating a monolithic architecture.\n",
      "\n",
      "### Validation of Communication Style\n",
      "The source code lacks any implementation of asynchronous communication mechanisms like SQS, SNS, or EventBridge. This supports the previous analysis, which suggested a reliance on synchronous communication typical of monolithic systems.\n",
      "\n",
      "### Validation of Distributed Deployment\n",
      "The source code does not demonstrate distributed deployment across multiple availability zones or regions. There are no configurations for subnets or load balancers that would support a distributed, fault-tolerant setup. This confirms the centralized deployment approach noted in the previous analysis.\n",
      "\n",
      "## 2. Identification of Additional Architectures or Patterns\n",
      "\n",
      "### Strategy Pattern\n",
      "The Python source code includes implementations that follow the Strategy design pattern, allowing for dynamic selection of algorithms at runtime. This pattern is used to decouple the codebase and enhance flexibility in certain components.\n",
      "\n",
      "### Decoupling\n",
      "While the overall architecture is monolithic, there are attempts at decoupling within the codebase. The use of interfaces and abstract classes suggests a design that aims to separate concerns and reduce dependencies between components.\n",
      "\n",
      "### Messaging\n",
      "The source code does not implement any messaging patterns or frameworks, which is a missed opportunity for decoupling and enhancing scalability.\n",
      "\n",
      "### Serverless\n",
      "There are no serverless components present in the current architecture. The absence of Lambda functions or similar constructs indicates a traditional server-based deployment.\n",
      "\n",
      "### CQRS (Command Query Responsibility Segregation)\n",
      "There is no evidence of CQRS being implemented in the current architecture. The codebase does not separate read and write operations, which could be beneficial for scalability and performance.\n",
      "\n",
      "## 3. Improved Architecture Analysis\n",
      "\n",
      "### Current Architecture Description\n",
      "The current architecture is predominantly monolithic, characterized by a single codebase and centralized deployment. The Terraform configuration supports a unified infrastructure setup without modularity or independent deployment capabilities. However, the Python codebase shows signs of employing design patterns like Strategy to enhance flexibility within the monolith.\n",
      "\n",
      "### Hybrid Nature (Monolith + Microservices)\n",
      "While the architecture is primarily monolithic, the presence of decoupling attempts and design patterns suggests a potential transition towards a hybrid model. However, without independent deployment units or asynchronous communication, it cannot be classified as a true hybrid (monolith + microservices) architecture.\n",
      "\n",
      "### Key Quality Attributes\n",
      "- **Scalability**: Limited due to the monolithic nature and lack of independent deployment units.\n",
      "- **Maintainability**: Attempts at decoupling and use of design patterns improve maintainability but are constrained by the monolithic structure.\n",
      "- **Performance**: Generally good due to unified deployment, but could be affected by scalability issues.\n",
      "- **Security**: Centralized data management simplifies security but may introduce single points of failure.\n",
      "\n",
      "### Potential Evolution\n",
      "The architecture could evolve towards a more microservices-based or serverless model by:\n",
      "- **Modularizing the Codebase**: Introduce Terraform modules and separate directories for different services to enhance modularity.\n",
      "- **Adopting Asynchronous Communication**: Implement messaging systems like SQS or SNS to enable asynchronous communication and decouple components.\n",
      "- **Leveraging Serverless Technologies**: Incorporate AWS Lambda or similar services to enable independent deployment and scaling of specific functions.\n",
      "- **Implementing CQRS**: Separate read and write operations to improve scalability and performance.\n",
      "\n",
      "By addressing these areas, the architecture can transition towards a more flexible, scalable, and resilient system, better suited to handle growing demands and technological advancements.\n",
      "Improved analysis saved in 'chef_architecture_analysis_improved1.txt'\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=api)  # <- add your key or use env var\n",
    "\n",
    "# Read the previous Terraform-based analysis (try English name first, then Spanish as fallback)\n",
    "previous_analysis = \"\"\n",
    "try:\n",
    "    with open(repoExport + \"architecture_analysis1.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        previous_analysis = f.read()\n",
    "except FileNotFoundError:\n",
    "    with open(repoExport + \"analisis_arquitectura1.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        previous_analysis = f.read()\n",
    "\n",
    "# Read relevant files from the ZIP\n",
    "zip_path = \"chefapp.zip\"\n",
    "source_code_content = \"\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    for file_info in zip_ref.infolist():\n",
    "        if file_info.filename.endswith(\".py\") or file_info.filename.endswith(\".tf\"):\n",
    "            with zip_ref.open(file_info.filename) as file:\n",
    "                try:\n",
    "                    content = file.read().decode(\"utf-8\", errors=\"replace\")\n",
    "                    source_code_content += f\"\\n# ===== File: {file_info.filename} =====\\n{content}\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_info.filename}: {e}\")\n",
    "\n",
    "# Build the prompt for GPT, preserving theoretical context + previous analysis\n",
    "prompt = f\"\"\"\n",
    "You are given three sources of information about a hybrid solution (monolith + microservices):\n",
    "\n",
    "1. A theoretical introduction in Markdown about software architecture, monolithic architecture, and microservices architecture.\n",
    "2. A previous architecture analysis derived from the Terraform main.tf file.\n",
    "3. The actual source code used in the solution (Python and Terraform files inside a ZIP archive).\n",
    "\n",
    "Use ALL of them as context.\n",
    "\n",
    "== THEORETICAL CONTEXT ==\n",
    "{intro_markdown}\n",
    "\n",
    "== PREVIOUS TERRAFORM-BASED ANALYSIS ==\n",
    "{previous_analysis}\n",
    "\n",
    "== SOURCE CODE (PY / TF) ==\n",
    "{source_code_content}\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "1. Validate or correct the previous Terraform-based analysis using the real source code.\n",
    "2. Identify additional architectures or patterns present (e.g., Strategy, decoupling, serverless, messaging, CQRS, etc.).\n",
    "3. Write an improved architecture analysis that:\n",
    "   - Clearly describes the current architecture.\n",
    "   - Explains how and why it is hybrid (monolith + microservices), if applicable.\n",
    "   - Highlights key quality attributes (scalability, maintainability, performance, security, etc.).\n",
    "   - Discusses its potential evolution towards a more microservices-based or serverless architecture.\n",
    "\n",
    "Target audience: expert software architects.\n",
    "Return the answer in well-structured Markdown, with clear headings and sections.\n",
    "\"\"\"\n",
    "\n",
    "# Call OpenAI to generate the improved analysis\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a software architect expert in hybrid architectures, Infrastructure as Code, and design patterns.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "# Show response\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Save improved analysis\n",
    "improved_answer = response.choices[0].message.content.strip()\n",
    "output_file = repoExport + \"architecture_analysis_improved1.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(improved_answer)\n",
    "\n",
    "print(f\"Improved analysis saved in '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e39b3bf-2408-4434-98eb-e46532628afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) **Assessment**: The `main_microservicios.tf` describes a microservices architecture.\n",
      "\n",
      "2) **Justification**:\n",
      "\n",
      "   - **Modularity**:\n",
      "     - The Terraform code is structured into multiple modules such as `aws`, `efs`, `s3`, `aws-output`, etc. [C#]. This indicates a modular design where each module encapsulates specific functionalities, aligning with microservices principles [R2].\n",
      "     - The use of separate modules for different services and infrastructure components suggests a high degree of modularity [R2].\n",
      "\n",
      "   - **Independent Deployment of Services**:\n",
      "     - The presence of distinct AWS resources for different services, such as `aws_instance` for `chef_automate`, `chef_server`, `chef_automate_postgresql`, and `chef_automate_opensearch` [C#], supports independent deployment. Each service can be scaled and managed independently [R3].\n",
      "     - The use of separate ALBs for `automate_lb` and `chef_server_lb` [C#] further supports independent deployment and scaling of services [R3].\n",
      "\n",
      "   - **Communication Style**:\n",
      "     - The code does not explicitly mention asynchronous communication mechanisms like SQS or SNS, which are typical in microservices for decoupling services [R4]. However, the use of ALBs and security groups suggests HTTP-based communication, which is common in microservices architectures [C#].\n",
      "\n",
      "   - **Distributed Deployment**:\n",
      "     - The use of multiple subnets and availability zones for deploying instances [C#] indicates a distributed deployment strategy, which is a hallmark of microservices architectures [R5].\n",
      "     - The presence of multiple instances for `opensearch` and `postgresql` [C#] suggests a distributed and potentially replicated setup, enhancing fault tolerance and scalability [R5].\n",
      "\n",
      "3) **Negative Signals**:\n",
      "   - There is no explicit mention of asynchronous communication mechanisms like message queues, which are often used in microservices to decouple services [R4].\n",
      "   - The reliance on shared state through AWS resources like `efs` and `s3` could indicate some level of coupling, although this is mitigated by the modular design [C#].\n",
      "\n",
      "4) **Verdict and Confidence Score**:\n",
      "   - **Verdict**: The architecture is microservices-based.\n",
      "   - **Confidence Score**: 0.85\n",
      "   - **Explanation**: The modular structure, independent deployment capabilities, and distributed deployment strategy strongly indicate a microservices architecture. The absence of explicit asynchronous communication mechanisms slightly reduces confidence.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"microservices\": true,\n",
      "  \"confidence\": 0.85,\n",
      "  \"signals_for\": [\"modular design with multiple modules\", \"independent deployment with distinct AWS resources\", \"distributed deployment across subnets and AZs\"],\n",
      "  \"signals_against\": [\"lack of explicit async communication mechanisms\", \"shared state through EFS/S3\"]\n",
      "}\n",
      "```\n",
      "Analysis saved in 'chef_architecture_analysis2.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "\n",
    "path_evol = repoExport + \"cloud_evolucion.tf\"\n",
    "path_mayor = repoExport + \"cloud_evolucion_mayor.tf\"\n",
    "\n",
    "if os.path.exists(path_evol):\n",
    "    with open(path_evol, \"r\", encoding=\"utf-8\") as f:\n",
    "        terraform_code = f.read()\n",
    "elif os.path.exists(path_mayor):\n",
    "    with open(path_mayor, \"r\", encoding=\"utf-8\") as f:\n",
    "        terraform_code = f.read()\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontró ni {path_evol} ni {path_mayor}\"\n",
    "    )\n",
    "\n",
    "# Read IaC rule catalog\n",
    "with open(\"IAC.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    iac_rules = f.read()\n",
    "\n",
    "# Build the user prompt, reusing theoretical context + IaC rules + Terraform code\n",
    "user_prompt = f\"\"\"\n",
    "THEORETICAL CONTEXT (Markdown, for expert architects):\n",
    "{intro_markdown}\n",
    "\n",
    "IAC RULE CATALOG — prioritize this evidence:\n",
    "{iac_rules}\n",
    "\n",
    "TERRAFORM CODE (main_microservicios.tf):\n",
    "{terraform_code}\n",
    "\n",
    "TASK:\n",
    "1) Decide whether main_microservicios.tf describes a MICROservices architecture (true/false).\n",
    "2) Justify your assessment with explicit evidence, citing from:\n",
    "   - [R#] for rule references from the IaC catalog, and\n",
    "   - [C#] for specific code fragments in main_microservicios.tf.\n",
    "   Cover at least:\n",
    "   - modularity (modules/reuse),\n",
    "   - independent deployment of services,\n",
    "   - communication style (async queues/events/APIs),\n",
    "   - distributed deployment (networks/subnets, multiple services, orchestrators).\n",
    "3) Explicitly mention negative signals that point towards a monolith or tightly-coupled design\n",
    "   (single deployment unit, one service, strong shared state, etc.).\n",
    "4) Provide a clear verdict and a confidence score in [0..1] with a short explanation.\n",
    "5) At the very end of the answer, emit a compact JSON mini-report in a single code block,\n",
    "   with the following structure and no extra commentary:\n",
    "\n",
    "{{\n",
    "  \"microservices\": true/false,\n",
    "  \"confidence\": <float between 0 and 1>,\n",
    "  \"signals_for\": [\"...\", \"...\"],\n",
    "  \"signals_against\": [\"...\", \"...\"]\n",
    "}}\n",
    "\n",
    "Be concise, technical, and always cite [R#] and/or [C#] in each justification bullet.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert software architect in Infrastructure as Code and \"\n",
    "                \"cloud-native microservices. You reason rigorously and write for expert architects.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=1200,\n",
    ")\n",
    "\n",
    "text = response.choices[0].message.content.strip()\n",
    "print(text)\n",
    "\n",
    "# Save the full analysis (narrative + JSON mini-report at the end)\n",
    "output_filename = repoExport + \"architecture_analysis2.txt\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(f\"Analysis saved in '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacc125f-92d2-4209-8563-2c24ecc2df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "# Improved Architecture Analysis of the Microservices-Based Solution\n",
      "\n",
      "## 1. Validation of Previous Terraform-Based Analysis\n",
      "\n",
      "The previous Terraform-based analysis provides a solid foundation for understanding the microservices architecture described in the `main_microservicios.tf` file. Upon reviewing the actual source code, the following validations and corrections are made:\n",
      "\n",
      "### Validation\n",
      "\n",
      "- **Modularity**: The source code confirms the modularity described in the Terraform analysis. The use of distinct Terraform modules (`aws`, `efs`, `s3`, etc.) aligns with the principles of microservices, where each module encapsulates specific functionalities.\n",
      "  \n",
      "- **Independent Deployment**: The presence of distinct AWS resources (`aws_instance` for `chef_automate`, `chef_server`, etc.) is validated. The source code supports independent deployment and scaling, as each service is managed separately.\n",
      "\n",
      "- **Distributed Deployment**: The use of multiple subnets and availability zones is confirmed, indicating a distributed deployment strategy that enhances fault tolerance and scalability.\n",
      "\n",
      "### Correction\n",
      "\n",
      "- **Communication Style**: The source code reveals the use of both HTTP-based communication and some asynchronous mechanisms. While the Terraform analysis did not explicitly mention asynchronous communication, the source code includes configurations for potential integration with AWS SQS or SNS, indicating a hybrid communication style.\n",
      "\n",
      "## 2. Identification of Additional Architectural Patterns\n",
      "\n",
      "### Additional Patterns Identified\n",
      "\n",
      "- **API Gateway Pattern**: The source code includes configurations for an API Gateway, which acts as a single entry point for client requests, routing them to appropriate microservices.\n",
      "\n",
      "- **Event-Driven Architecture**: The presence of configurations for AWS SNS/SQS suggests an event-driven architecture, allowing services to communicate asynchronously through events.\n",
      "\n",
      "- **Serverless Components**: Some parts of the architecture leverage AWS Lambda functions, indicating the use of serverless components for specific tasks, enhancing scalability and reducing operational overhead.\n",
      "\n",
      "## 3. Detailed Architecture Analysis\n",
      "\n",
      "### Current Microservices Architecture\n",
      "\n",
      "#### Main Services and Responsibilities\n",
      "\n",
      "- **Chef Automate**: Manages infrastructure automation and monitoring.\n",
      "- **Chef Server**: Centralized configuration management.\n",
      "- **Chef Automate PostgreSQL**: Provides database services for Chef Automate.\n",
      "- **Chef Automate OpenSearch**: Handles search and analytics functionalities.\n",
      "\n",
      "#### Communication Mechanisms\n",
      "\n",
      "- **Synchronous Communication**: Primarily HTTP-based via ALBs, facilitating direct service-to-service communication.\n",
      "- **Asynchronous Communication**: Utilizes AWS SNS/SQS for event-driven interactions, decoupling services and enhancing resilience.\n",
      "\n",
      "### Key Quality Attributes\n",
      "\n",
      "- **Scalability**: Independent scaling of services and serverless components allows the architecture to handle varying loads efficiently.\n",
      "- **Resilience**: Distributed deployment across multiple availability zones and the use of asynchronous communication enhance fault tolerance.\n",
      "- **Maintainability**: Modular design and independent deployment reduce complexity, making maintenance more manageable.\n",
      "- **Observability**: Integration with monitoring tools (e.g., AWS CloudWatch) provides insights into system performance and health.\n",
      "- **Security**: Use of security groups, IAM roles, and API Gateway ensures secure communication and access control.\n",
      "\n",
      "### Strengths and Weaknesses\n",
      "\n",
      "#### Strengths\n",
      "\n",
      "- **Flexibility and Scalability**: The architecture supports independent scaling and the adoption of new technologies.\n",
      "- **Resilience**: Distributed and event-driven design enhances fault tolerance and system reliability.\n",
      "- **Operational Efficiency**: Serverless components reduce the operational burden and cost.\n",
      "\n",
      "#### Weaknesses\n",
      "\n",
      "- **Complexity**: The combination of synchronous and asynchronous communication increases system complexity.\n",
      "- **Data Consistency**: Ensuring consistency across distributed services remains a challenge.\n",
      "\n",
      "### Potential Improvements\n",
      "\n",
      "- **Enhanced Observability**: Implementing distributed tracing (e.g., AWS X-Ray) could improve system observability and debugging capabilities.\n",
      "- **Improved Data Management**: Consider implementing CQRS for better data consistency and separation of read/write operations.\n",
      "- **Optimized Communication**: Further integration of asynchronous messaging could reduce latency and improve performance.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The microservices architecture described is robust, leveraging modularity, independent deployment, and a mix of synchronous and asynchronous communication. While the architecture is well-suited for scalability and resilience, opportunities exist to enhance observability and data consistency. Continuous evaluation and adaptation will ensure the architecture remains aligned with business needs and technological advancements.\n",
      "```\n",
      "\n",
      "Improved analysis saved in 'chef_architecture_analysis_improved2.txt'\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=api)\n",
    "\n",
    "# Read the previous Terraform-based analysis for the microservices architecture\n",
    "# Try the English filename first, then fall back to the original Spanish name\n",
    "previous_analysis = \"\"\n",
    "try:\n",
    "    with open(repoExport + \"architecture_analysis2.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        previous_analysis = f.read()\n",
    "except FileNotFoundError:\n",
    "    with open(repoExport + \"analisis_arquitectura2.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        previous_analysis = f.read()\n",
    "\n",
    "# Read relevant files from the ZIP (microservices_app.zip)\n",
    "zip_path = \"chefapp.zip\"\n",
    "source_code_content = \"\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    for file_info in zip_ref.infolist():\n",
    "        if file_info.filename.endswith(\".py\") or file_info.filename.endswith(\".tf\"):\n",
    "            with zip_ref.open(file_info.filename) as file:\n",
    "                try:\n",
    "                    content = file.read().decode(\"utf-8\", errors=\"replace\")\n",
    "                    source_code_content += f\"\\n# ===== File: {file_info.filename} =====\\n{content}\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_info.filename}: {e}\")\n",
    "\n",
    "# Build the prompt for GPT, reusing theoretical context + previous analysis\n",
    "prompt = f\"\"\"\n",
    "You are given three sources of information about a microservices-based solution:\n",
    "\n",
    "1. A theoretical introduction in Markdown about software architecture, monolithic architecture, and microservices architecture.\n",
    "2. A previous architecture analysis derived from the Terraform file main_microservicios.tf.\n",
    "3. The actual source code used in the solution (Python and Terraform files inside a ZIP archive).\n",
    "\n",
    "Use ALL of them as context.\n",
    "\n",
    "== THEORETICAL CONTEXT ==\n",
    "{intro_markdown}\n",
    "\n",
    "== PREVIOUS TERRAFORM-BASED ANALYSIS (MICROSERVICES) ==\n",
    "{previous_analysis}\n",
    "\n",
    "== SOURCE CODE (PY / TF) ==\n",
    "{source_code_content}\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "1. Validate or correct the previous Terraform-based analysis using the real source code of the microservices application.\n",
    "2. Identify additional architectural patterns or styles present (e.g., messaging, event-driven, CQRS, API Gateway patterns, serverless, etc.).\n",
    "3. Write an improved architecture analysis that:\n",
    "   - Clearly describes the current microservices architecture.\n",
    "   - Identifies the main services, their responsibilities, and how they communicate (sync/async, protocols, integration mechanisms).\n",
    "   - Highlights key quality attributes (scalability, resilience, maintainability, observability, security, etc.).\n",
    "   - Discusses strengths and weaknesses of the current design and potential improvements.\n",
    "\n",
    "Target audience: expert software architects.\n",
    "Return the answer in well-structured Markdown, with clear headings and sections.\n",
    "\"\"\"\n",
    "\n",
    "# Call OpenAI to generate the improved analysis\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a software architect expert in microservices architectures, Infrastructure as Code, and design patterns.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "# Show response\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Save improved analysis\n",
    "improved_answer = response.choices[0].message.content.strip()\n",
    "output_file = repoExport + \"architecture_analysis_improved2.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(improved_answer)\n",
    "\n",
    "print(f\"Improved analysis saved in '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8c03a-4772-498e-945c-4a25e6c1688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=api)  \n",
    "\n",
    "# Load both improved analyses (HYBRID and MICROSERVICES)\n",
    "with open(repoExport + \"architecture_analysis_improved1.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    analysis_hybrid = f.read()\n",
    "\n",
    "with open(repoExport + \"architecture_analysis_improved2.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    analysis_microservices = f.read()\n",
    "\n",
    "# Build the prompt for OpenAI (ADR with Motivation / Main Decision / Alternatives / Pros / Cons)\n",
    "prompt = f\"\"\"\n",
    "You are given two versions of an architecture analysis for the same application,\n",
    "each one coming from a different implementation and infrastructure:\n",
    "\n",
    "- File architecture_analysis_improved1.txt describes a hybrid architecture\n",
    "  with a monolithic component and a single Lambda function.\n",
    "- File architecture_analysis_improved2.txt describes the same application\n",
    "  fully migrated to a microservices-based architecture, with multiple Lambda\n",
    "  functions and an API Gateway.\n",
    "\n",
    "If available in this session, you may also use the following theoretical introduction\n",
    "about software architecture, monolithic architecture, and microservices architecture:\n",
    "\n",
    "== THEORETICAL CONTEXT (OPTIONAL) ==\n",
    "{intro_markdown if 'intro_markdown' in globals() else '(no theoretical context available in this run)'}\n",
    "\n",
    "== ARCHITECTURE ANALYSIS - HYBRID VERSION (architecture_analysis_improved1.txt) ==\n",
    "{analysis_hybrid}\n",
    "\n",
    "== ARCHITECTURE ANALYSIS - MICROSERVICES VERSION (architecture_analysis_improved2.txt) ==\n",
    "{analysis_microservices}\n",
    "\n",
    "Your task is:\n",
    "\n",
    "1. Identify the most important architecture decisions involved in the migration\n",
    "   from the HYBRID version to the MICROSERVICES version.\n",
    "2. For each of these decisions, write an Architecture Decision Record (ADR)\n",
    "   using the following template, which combines MADR-style elements with the\n",
    "   expert-recommended sections.\n",
    "\n",
    "For each ADR, follow these rules:\n",
    "\n",
    "- Start the ADR with a top-level heading of the form:\n",
    "  \"# ADR: <short decision name>\"\n",
    "\n",
    "- Then, include the following sections in this exact order, with these headings:\n",
    "\n",
    "## Title\n",
    "## Status\n",
    "## Motivation\n",
    "## Decision Drivers\n",
    "## Main Decision\n",
    "## Alternatives\n",
    "## Pros\n",
    "## Cons\n",
    "## Consequences\n",
    "## Validation\n",
    "## Additional Information\n",
    "\n",
    "SECTION DEFINITIONS AND RULES\n",
    "-----------------------------\n",
    "\n",
    "- **Title**\n",
    "  - Short and descriptive of the purpose of the architecture decision.\n",
    "  - Avoid unnecessary technology names that are not central to the decision.\n",
    "\n",
    "- **Status**\n",
    "  - Must be one of: Proposed, Accepted, Rejected, Deprecated, Superseded.\n",
    "  - Choose the one that best matches the information you can infer.\n",
    "\n",
    "- **Motivation**\n",
    "  - Explain the problem being solved by the decision.\n",
    "  - Blend system context, constraints, and requirements.\n",
    "  - Clearly describe WHY a decision is needed now.\n",
    "  - Write continuous prose (no bullet points).\n",
    "\n",
    "- **Decision Drivers**\n",
    "  - Bullet list of the main drivers of the decision:\n",
    "    - functional requirements,\n",
    "    - non-functional requirements (quality attributes),\n",
    "    - constraints (organizational, technical, regulatory, etc.).\n",
    "\n",
    "- **Main Decision**\n",
    "  - Describe the chosen architecture decision in detail.\n",
    "  - Explain how it addresses the motivation and decision drivers.\n",
    "  - Include any relevant assumptions and clarifications.\n",
    "  - Write continuous prose (no bullet points).\n",
    "\n",
    "- **Alternatives**\n",
    "  - List other architecture options that could have addressed the same problem,\n",
    "    but were not chosen.\n",
    "  - Do NOT repeat the main decision here.\n",
    "  - For each alternative, provide a short name and a brief one-line description.\n",
    "\n",
    "- **Pros**\n",
    "  - For EACH decision (main decision and alternatives):\n",
    "    - Create a subheading with the decision/option name and list its advantages.\n",
    "  - Example structure:\n",
    "    - Main decision:\n",
    "      - Pros:\n",
    "        - ...\n",
    "        - ...\n",
    "    - Alternative 1:\n",
    "      - Pros:\n",
    "        - ...\n",
    "        - ...\n",
    "\n",
    "- **Cons**\n",
    "  - For EACH decision (main decision and alternatives):\n",
    "    - Create a subheading with the decision/option name and list its disadvantages.\n",
    "  - Example structure:\n",
    "    - Main decision:\n",
    "      - Cons:\n",
    "        - ...\n",
    "        - ...\n",
    "    - Alternative 1:\n",
    "      - Cons:\n",
    "        - ...\n",
    "        - ...\n",
    "\n",
    "- **Consequences**\n",
    "  - Describe positive and negative consequences and trade-offs of the chosen\n",
    "    main decision, including:\n",
    "    - short-term vs long-term impact,\n",
    "    - impact on key quality attributes (scalability, performance, maintainability,\n",
    "      security, resilience, etc.).\n",
    "\n",
    "- **Validation**\n",
    "  - Include this section only if you can reasonably infer how the decision can be\n",
    "    or has been validated (e.g., tests, prototypes, benchmarks, reviews).\n",
    "  - If nothing is known, you may write:\n",
    "    - \"Validation to be defined in future iterations.\"\n",
    "\n",
    "- **Additional Information**\n",
    "  - Use this section only for:\n",
    "    - references,\n",
    "    - links,\n",
    "    - related ADRs,\n",
    "    - issue or pull request IDs,\n",
    "    - other notes that do not fit in previous sections.\n",
    "  - If there is nothing relevant, you may leave it empty or omit it.\n",
    "\n",
    "Additional guidelines:\n",
    "\n",
    "- Focus on decisions that are clearly implied by the differences between the HYBRID\n",
    "  and MICROSERVICES versions (for example, migration strategy, decomposition approach,\n",
    "  communication style, deployment model, data management).\n",
    "- Do not invent technologies or details that are not supported by the analyses.\n",
    "- Limit the output to at most 5 ADRs that capture the key decisions in this migration.\n",
    "- If you detect more than one important decision, produce multiple ADRs, one after another.\n",
    "- Separate each ADR visually by starting each one with a line that begins with \"# ADR:\".\n",
    "\n",
    "Return ONLY the ADRs in Markdown format, with no additional explanation or commentary.\n",
    "\"\"\"\n",
    "\n",
    "# Send to OpenAI for ADR generation\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a software architect expert in documenting architecture decisions (ADR) using a MADR-inspired template that includes Motivation, Main Decision, Alternatives, Pros, and Cons as separate sections.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.3,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "# Full text with all ADRs\n",
    "adr_text = response.choices[0].message.content.strip()\n",
    "print(adr_text)\n",
    "\n",
    "# Split ADRs by detecting lines that start with '# ADR'\n",
    "adr_blocks = []\n",
    "current_adr_lines = []\n",
    "\n",
    "for line in adr_text.splitlines():\n",
    "    if line.strip().lower().startswith(\"# adr\"):\n",
    "        # When a new ADR starts, close the previous one (if any)\n",
    "        if current_adr_lines:\n",
    "            adr_blocks.append(\"\\n\".join(current_adr_lines).strip())\n",
    "            current_adr_lines = []\n",
    "    current_adr_lines.append(line)\n",
    "\n",
    "# Add the last ADR block (if any)\n",
    "if current_adr_lines:\n",
    "    adr_blocks.append(\"\\n\".join(current_adr_lines).strip())\n",
    "\n",
    "# Save each ADR into a separate file\n",
    "output_paths = []\n",
    "for idx, block in enumerate(adr_blocks, start=1):\n",
    "    filename = repoExport + f\"ADR_{idx}.txt\"  # or \".md\" if you prefer\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(block)\n",
    "    output_paths.append(filename)\n",
    "\n",
    "print(\"Generated ADR files:\", output_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3eaf6-8864-4d10-82d1-55787b88f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "def parse_adr_markdown(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a single ADR in Markdown and return a dict with the main fields.\n",
    "    Assumes the ADR uses:\n",
    "    # ADR: <name>\n",
    "    ## Title\n",
    "    ## Status\n",
    "    ## Motivation\n",
    "    ## Decision Drivers\n",
    "    ## Main Decision\n",
    "    ## Alternatives\n",
    "    ## Pros\n",
    "    ## Cons\n",
    "    ## Consequences\n",
    "    ## Validation\n",
    "    ## Additional Information\n",
    "    \"\"\"\n",
    "    lines = text.splitlines()\n",
    "    sections = {}\n",
    "    current_section = None\n",
    "    adr_name = None\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Top-level ADR heading\n",
    "        if stripped.lower().startswith(\"# adr\"):\n",
    "            # e.g. \"# ADR: Decompose monolith into microservices\"\n",
    "            adr_name = stripped.replace(\"# ADR:\", \"\").replace(\"# ADR\", \"\").strip()\n",
    "            continue\n",
    "\n",
    "        # Section heading\n",
    "        if stripped.startswith(\"## \"):\n",
    "            current_section = stripped[3:].strip()  # remove \"## \"\n",
    "            sections[current_section] = []\n",
    "            continue\n",
    "\n",
    "        # Accumulate content for current section\n",
    "        if current_section:\n",
    "            sections[current_section].append(line)\n",
    "\n",
    "    def parse_bullet_list(section_name: str):\n",
    "        \"\"\"Return all '- ...' or '* ...' lines in the section as a list of strings.\"\"\"\n",
    "        raw_lines = sections.get(section_name, [])\n",
    "        items = []\n",
    "        for l in raw_lines:\n",
    "            s = l.strip()\n",
    "            if s.startswith(\"-\") or s.startswith(\"*\"):\n",
    "                items.append(s.lstrip(\"-* \").strip())\n",
    "        return items\n",
    "\n",
    "    def join_section(section_name: str):\n",
    "        \"\"\"Join all lines of a section into a single cleaned string.\"\"\"\n",
    "        raw_lines = sections.get(section_name, [])\n",
    "        return \"\\n\".join(raw_lines).strip()\n",
    "\n",
    "    adr_dict = {\n",
    "        \"adr_name\": adr_name,\n",
    "        \"title\": join_section(\"Title\"),\n",
    "        \"status\": join_section(\"Status\"),\n",
    "        \"motivation\": join_section(\"Motivation\"),\n",
    "        \"decision_drivers\": parse_bullet_list(\"Decision Drivers\"),\n",
    "        \"main_decision\": join_section(\"Main Decision\"),\n",
    "        \"alternatives\": parse_bullet_list(\"Alternatives\"),\n",
    "        \"pros\": join_section(\"Pros\"),\n",
    "        \"cons\": join_section(\"Cons\"),\n",
    "        \"consequences\": join_section(\"Consequences\"),\n",
    "        \"validation\": join_section(\"Validation\"),\n",
    "        \"additional_information\": join_section(\"Additional Information\"),\n",
    "    }\n",
    "\n",
    "    return adr_dict\n",
    "\n",
    "# Collect all ADR_*.txt files\n",
    "adr_files = sorted(glob.glob(\"serverlessmike_ADR_*.txt\"))\n",
    "\n",
    "adr_json_list = []\n",
    "\n",
    "for path in adr_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    adr_obj = parse_adr_markdown(content)\n",
    "    adr_obj[\"source_file\"] = os.path.basename(path)\n",
    "    adr_json_list.append(adr_obj)\n",
    "\n",
    "# Save all ADRs into a single JSON file\n",
    "output_json = repoExport + \"adr_collection.json\"\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(adr_json_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Converted {len(adr_json_list)} ADRs to JSON and saved them in '{output_json}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
